{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRXUz8ey8jhm",
        "outputId": "4d13b8f0-77de-45a0-bd82-7464df6eb6fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download pt_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.pt.examples import sentences\n",
        "\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "texto = \"Oi eu sou o Ryan, e estou aprendendo NLP\"\n",
        "doc = nlp(texto)\n",
        "print(texto)\n",
        "\n",
        "\n",
        "'''\n",
        "note que a gente separa o texto em tokens e categoriza eles de acordo com a língua específica\n",
        "e a gente pode acessar vários atributos dos tokens como o texto, o tipo a categoria,etc ,\n",
        "o spacy faz um encoding do das strings para valores hashs de modo que minimize o uso de memória\n",
        "e também melhore a eficiência, para não acessar os hashs mas sim a string precisamos usar \"_\"\n",
        "após o atributo do token\n",
        "'''\n",
        "\n",
        "for token in doc:\n",
        "    #string\n",
        "    print(token.text, token.shape_, token.pos_, token.dep_)\n",
        "    #hash\n",
        "    print(token.text, token.shape, token.pos, token.dep)\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yu0h0Lh8371",
        "outputId": "a8ae2439-5437-4504-d205-44c596c812b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oi eu sou o Ryan, e estou aprendendo NLP\n",
            "Oi Xx ADP ROOT\n",
            "Oi 12204527652707022206 85 8206900633647566924\n",
            "\n",
            "\n",
            "eu xx PRON nsubj\n",
            "eu 4370460163704169311 95 429\n",
            "\n",
            "\n",
            "sou xxx AUX cop\n",
            "sou 4088098365541558500 87 411\n",
            "\n",
            "\n",
            "o x DET det\n",
            "o 11123243248953317070 90 415\n",
            "\n",
            "\n",
            "Ryan Xxxx PROPN parataxis\n",
            "Ryan 10887629174180191697 96 436\n",
            "\n",
            "\n",
            ", , PUNCT punct\n",
            ", 2593208677638477497 97 445\n",
            "\n",
            "\n",
            "e x CCONJ cc\n",
            "e 11123243248953317070 89 407\n",
            "\n",
            "\n",
            "estou xxxx AUX aux\n",
            "estou 13110060611322374290 87 405\n",
            "\n",
            "\n",
            "aprendendo xxxx VERB conj\n",
            "aprendendo 13110060611322374290 100 410\n",
            "\n",
            "\n",
            "NLP XXX PROPN obj\n",
            "NLP 3552942401566437853 96 434\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.pt.examples import sentences\n",
        "\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "texto = \"Oi eu sou o Ryan e estou aprendendo NLP A minha vida é ciências da computação. Sou da UFG\"\n",
        "doc = nlp(texto)\n",
        "assert doc.has_annotation(\"SENT_START\")\n",
        "for sent in doc.sents:\n",
        "  print(sent.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzc_ErXuApz6",
        "outputId": "cf93cc59-ac4c-413f-8c2a-93d45e460a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oi eu sou o Ryan e estou aprendendo NLP\n",
            "A minha vida é ciências da computação.\n",
            "Sou da UFG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**E se a gente fizer um código simples de análise de sentimentos?**"
      ],
      "metadata": {
        "id": "tK-TlUL0FW2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.pt.examples import sentences\n",
        "\n",
        "class Core:\n",
        "  def __init__(self, texto):\n",
        "    self.nlp = spacy.load(\"pt_core_news_sm\")\n",
        "    self.texto = texto.lower()\n",
        "    self.doc = nlp(self.texto)\n",
        "\n",
        "  def printa_tokenizacao(self):\n",
        "    for token in self.doc:\n",
        "      print(token.text, token.shape_, token.pos_, token.dep_)\n",
        "\n",
        "  def analisar_sentimento(self):\n",
        "    contador_bom = 0\n",
        "    contador_ruim = 0\n",
        "\n",
        "    '''\n",
        "    Uma ideia interessante seria pegar as raízes das palavras boas e ruins e comparar\n",
        "    umas com as outras, sairia um resultado bem mais interessante a nível de funcionabilidade\n",
        "    mas com um exemplo desses já é possível ter uma noção de como uma análise de sentimento funcionaria\n",
        "    '''\n",
        "\n",
        "    for token in self.doc:\n",
        "      if token.pos_ == \"ADJ\":\n",
        "        if token.text in [\"ruim\", \"chato\", \"triste\", \"instavel\", \"lento\"]:\n",
        "          contador_ruim += 1\n",
        "        elif token.text in [\"bom\", \"divertido\", \"legal\", \"estavel\", \"inteligente\"]:\n",
        "          contador_bom += 1\n",
        "\n",
        "    if contador_bom > contador_ruim:\n",
        "      print(\"Sentimento positivo\")\n",
        "    elif contador_bom < contador_ruim:\n",
        "      print(\"Sentimento negativo\")\n",
        "    else:\n",
        "      print(\"Sentimento neutro\")\n",
        "\n",
        "primeiro = Core(\"Aplicativo muito legal, mas os prêmios são ruins\")\n",
        "primeiro.printa_tokenizacao()\n",
        "primeiro.analisar_sentimento()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atToHMphGE4b",
        "outputId": "ac044f57-b932-46f4-f318-faed3e766828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aplicativo xxxx ADJ ROOT\n",
            "muito xxxx ADV advmod\n",
            "legal xxxx ADJ amod\n",
            ", , PUNCT punct\n",
            "mas xxx CCONJ cc\n",
            "os xx DET det\n",
            "prêmios xxxx NOUN nsubj\n",
            "são xxx AUX cop\n",
            "ruins xxxx ADJ conj\n",
            "Sentimento positivo\n"
          ]
        }
      ]
    }
  ]
}